from transformers import AutoModel
import numpy as np
import soundfile as sf
import os
import torch
import logging
from huggingface_hub import login

# ğŸ”¹ Configure Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# ğŸ”¹ Hugging Face Authentication
HF_TOKEN = "<Your huggingface token>"
login(HF_TOKEN)

# ğŸ”¹ Load IndicF5 model
repo_id = "ai4bharat/IndicF5"

try:
    model = AutoModel.from_pretrained(repo_id, trust_remote_code=True)
    logging.info("âœ… Model loaded successfully!")
except Exception as e:
    logging.error(f"âŒ Error loading model: {e}")
    exit(1)

# ğŸ”¹ Tamil + English Mixed Text for Synthesis (Tanglish)
text = "à®µà®£à®•à¯à®•à®®à¯! Today is a beautiful day. Let's enjoy and make good memories."

# ğŸ”¹ Tamil reference audio (Ensuring correct Tamil pronunciation)
ref_audio_path = "IndicF5/prompts/TAM_F_HAPPY_00001.wav"
ref_text = "à®µà®£à®•à¯à®•à®®à¯! à®‡à®©à¯à®±à¯ à®’à®°à¯ à®®à®•à®¿à®´à¯à®šà¯à®šà®¿à®¯à®¾à®© à®¨à®¾à®³à¯."

# ğŸ”¹ Check if reference audio exists
if not os.path.exists(ref_audio_path):
    logging.error(f"âŒ Reference audio file NOT found: {ref_audio_path}")
    exit(1)
logging.info(f"ğŸ“‚ Reference audio found: {ref_audio_path}")

# ğŸ”¹ Check if GPU is available, otherwise use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
logging.info(f"ğŸš€ Using device: {device}")
model.to(device)

# ğŸ”¹ Generate speech with explicit Tamil setting
try:
    logging.info("ğŸ¤ Generating speech using IndicF5 (Tamil + English Mode)...")
    
    # ğŸ”¹ Run model inference with Tamil language setting
    audio_data = model(text, ref_audio_path=ref_audio_path, ref_text=ref_text, language="ta")

    # ğŸ”¹ Validate if model returned proper audio
    if audio_data is None or len(audio_data) == 0:
        logging.error("âŒ No audio data generated!")
        exit(1)

    # ğŸ”¹ Function to normalize audio correctly
    def normalize_audio(audio_array):
        audio_array = np.asarray(audio_array)
        if audio_array.dtype != np.float32:
            audio_array = audio_array.astype(np.float32) / np.max(np.abs(audio_array))
        return audio_array

    # ğŸ”¹ Normalize and save output
    normalized_audio = normalize_audio(audio_data)

    output_dir = "IndicF5/output"
    output_filename = "tamil_english_speech.wav"
    output_path = os.path.join(output_dir, output_filename)

    # ğŸ”¹ Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # ğŸ”¹ Save the output with correct sampling rate
    sample_rate = 24000
    sf.write(output_path, normalized_audio, samplerate=sample_rate)

    # ğŸ”¹ Check if file exists
    if os.path.exists(output_path):
        logging.info(f"âœ… Tamil + English mixed speech generated successfully!")
        logging.info(f"ğŸ“‚ File saved at: {output_path}")
        logging.info(f"ğŸ’¾ File size: {os.path.getsize(output_path) / 1024:.2f} KB")
    else:
        logging.error("âŒ Tamil + English speech file was NOT created!")

except Exception as e:
    logging.error(f"âŒ Error generating speech: {e}")
